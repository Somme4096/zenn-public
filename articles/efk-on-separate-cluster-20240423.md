---
title: "Elastic Cloud on Kubernetes (ECK)ã§SaaSã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°ç›£è¦–ç’°å¢ƒã‚’æ§‹ç¯‰ã—ãŸè©±ã‚’ãªã‚‹ã¹ãè©³ã—ãæ›¸ã"
emoji: "ğŸ”­"
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢
topics: ["kubernetes","fluentd","elasticsearch","kibana"]
published: false
---

# ã¯ã˜ã‚ã«
Kubernetesã§B2B SaaSãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã‚’é‹ç”¨ã™ã‚‹ã«ã‚ãŸã‚Šã€ä¸€æ™‚é–“ã§åæ•°ä¸‡æ¡ã«ä¸Šã‚‹è†¨å¤§ãªé‡ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã‚’åŠ¹æœçš„ã«åé›†ã—ã¦æ¤œç´¢ã‚„åˆ†æã‚’è¡Œã†æ‰‹æ®µãŒå¿…è¦ã§ã—ãŸã€‚

ãã“ã§ã€ãƒ­ã‚°åé›†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®fluentdã‚’ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã®Kubernetesã‚¯ãƒ©ã‚¹ã‚¿ã«é…ç½®ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåé›†ã—ãŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã‚’ç›£è¦–ãŠã‚ˆã³å¯è¦–åŒ–ã™ã‚‹ãŸã‚ã«ã€ECKã‚’ç”¨ã„ã¦æ–°ãŸã«Elastic Stackã‚’ Linode Kubernetes Engine ä¸Šã«æ§‹ç¯‰ã—ã¾ã—ãŸã€‚

æœ¬è¨˜äº‹ã§ã¯ã€fluentdã«ã‚ˆã‚‹ãƒ­ã‚°ã®åé›†ãŠã‚ˆã³ElasticSearchã¸ã®é€ä¿¡ã€Elastic Stackã®æ§‹ç¯‰ãŠã‚ˆã³Kibanaãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®Ingressã«ã‚ˆã‚‹å…¬é–‹ã¨ç°¡ç•¥ãªSSLèªè¨¼ã¾ã§ã‚«ãƒãƒ¼ã—ã¾ã™ã€‚

## ECKã¨ã¯ï¼Ÿ
**ECK**(**E**lastic **C**loud on **K**ubernetes)ã¯ElasticSearchã‚„Kibanaãªã©ã‚’å«ã‚€Elastic Stackã®CRD/Operatorã§ã€Kubernetesã¸ã®Elastic Stackã®ãƒ‡ãƒ—ãƒ­ã‚¤ã¨ç®¡ç†ã‚’åŠ¹ç‡åŒ–ã—ã¾ã™ã€‚

å…·ä½“çš„ã«ã¯ã€ElasticSearchã‚„Kibanaã€APM serverãªã©å€‹ã€…ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚«ã‚¹ã‚¿ãƒ ãƒªã‚½ãƒ¼ã‚¹ã‚’å®šç¾©ã—ã€å®šç¾©ã•ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ç®¡ç†ã‚’è‡ªå‹•åŒ–ã—ã¾ã™ã€‚
:::message
(24/07/23)ç¾åœ¨ã€å…¬å¼ã«æ¨å¥¨ã•ã‚Œã‚‹Elastic Stackã®Kubernetesã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤æ–¹æ³•ã§ã™ã€‚
:::

## å‹•ä½œç’°å¢ƒ
#### åé›†å´ã‚¯ãƒ©ã‚¹ã‚¿ï¼ˆSaaSãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ï¼‰
- LKE (Linode Kubernetes Engine) Dedicated 32GB
:::message
å®Ÿéš›ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹åé›†ç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®fluentdã¯ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡~200mbã»ã©ã®å°ã•ã„ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚ã‚‹ãŸã‚ã€å¤§æŠµã®ç’°å¢ƒã§å‹•ä½œã§ãã¾ã™ã€‚ãã®ãŸã‚ã€ã“ã“ã§ã¯åé›†å´ã‚¯ãƒ©ã‚¹ã‚¿ã®ã‚¹ãƒšãƒƒã‚¯ã¯æ˜è¨˜ã—ã¾ã›ã‚“ã€‚
:::
#### Elastic Stackç”¨ã‚¯ãƒ©ã‚¹ã‚¿
- LKE (Linode Kubernetes Engine) Dedicated 8GB plan x 1
  - 2 CPU
  - 8GB RAM
  - 160GB Storage
  - 5TB Transfer
  - 40/5Gbps Network In/Out
- Linode Block Storageï¼ˆå¾“é‡èª²é‡‘åˆ¶ï¼‰
  - å—ä¿¡ã—ãŸãƒ­ã‚°ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã«ä½¿ç”¨

:::message alert
LKEã‚’åˆ©ç”¨ã—ã¦ã„ã‚‹å ´åˆã€Dedicated 8GBä»¥ä¸‹ã®ãƒ—ãƒ©ãƒ³ã¯ãƒªã‚½ãƒ¼ã‚¹ä¸è¶³ã§Elastic StackãŒèµ·å‹•ã§ãã¾ã›ã‚“ã€‚å¯èƒ½ã§ã‚ã‚Œã°ã€Dedicated 8GB x3å°ã®æ§‹æˆãŒæœ›ã¾ã—ã„ã¨æ€ã‚ã‚Œã¾ã™ã€‚
:::
# 1.Elastic Stackã®æ§‹ç¯‰
:::message
(**24/07/23**)ç¾åœ¨ã€æœ€æ–°ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã‚ã‚‹8.14.3ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™ã€‚ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹Kubernetesãƒãƒ¼ã‚¸ãƒ§ãƒ³ãªã©ã¯ã“ã¡ã‚‰(https://www.elastic.co/guide/en/cloud-on-k8s/current/k8s-quickstart.html)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
:::

## 1.1 å‰æã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
ã¾ãšã¯å…¬å¼ã‚¬ã‚¤ãƒ‰ã‚’å‚è€ƒã—ã¦ã€ã‚«ã‚¹ã‚¿ãƒ ãƒªã‚½ãƒ¼ã‚¹(CRD)ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

```bash
kubectl create -f https://download.elastic.co/downloads/eck/2.13.0/crds.yaml
```
```
customresourcedefinition.apiextensions.k8s.io/agents.agent.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/apmservers.apm.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/beats.beat.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/elasticmapsservers.maps.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/elasticsearches.elasticsearch.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/enterprisesearches.enterprisesearch.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/kibanas.kibana.k8s.elastic.co created
customresourcedefinition.apiextensions.k8s.io/logstashes.logstash.k8s.elastic.co created
```
æ¬¡ã«ã€Operatorã¨RBACãƒ«ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚
```bash
kubectl apply -f https://download.elastic.co/downloads/eck/2.13.0/operator.yaml
```
## 1.2 ElasticSearchã¨Kibanaã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

## 1.3 Ingress Controllerã‚’ä½¿ç”¨ã—ã¦Kibanaã‚’å…¬é–‹ã™ã‚‹

å…ˆã»ã©`kubectl port-forwarding`ã§Kibanaã®å‹•ä½œç¢ºèªãŒã§ãã¾ã—ãŸãŒã€ç¾åœ¨ã®çŠ¶æ…‹ã§ã¯å¤–éƒ¨ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“ã€‚ã¨ã„ã†ã®ã‚‚ã€`kubectl get svc`ã§ç¢ºèªã™ã‚‹ã¨ã€
```
NAME                                 TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)          AGE
logging-dashboard-es-default         ClusterIP      None             <none>          9200/TCP         41h
logging-dashboard-es-http            ClusterIP      10.128.5.221     <none>          9200/TCP         41h
logging-dashboard-es-internal-http   ClusterIP      10.128.238.88    <none>          9200/TCP         41h
logging-dashboard-es-transport       ClusterIP      None             <none>          9300/TCP         41h
logging-dashboard-kb-http            ClusterIP      10.128.185.177   <none>          5601/TCP         41h
```
å¤–éƒ¨ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ãŸã„Kibanaã®Serviceã§ã‚ã‚‹`logging-dashboard-kb-http`ã¯ã‚¿ã‚¤ãƒ—ãŒã‚¯ãƒ©ã‚¹ã‚¿ã®å†…éƒ¨é€šä¿¡ã«ä½¿ã‚ã‚Œã‚‹`ClusterIP`ã§ã€`EXTERNAL-IP`ãŒç©ºæ¬„ã«ãªã£ã¦ã„ã¦ã„ã‚‹ã“ã¨ã‹ã‚‰å…¬é–‹IPã‚¢ãƒ‰ãƒ¬ã‚¹ãŒå‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¦ã„ãªã„ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚

ã“ã®Serviceã®å¤–éƒ¨ã‚¢ã‚¯ã‚»ã‚¹ã‚’å¯èƒ½ã™ã‚‹ã«ã¯`LoadBalancer`ã‚¿ã‚¤ãƒ—ã®Serviceã‚’æ–°ãŸã«ä½œã‚‹æ‰‹æ³•ã‚‚ã‚ã‚Šã¾ã™ãŒã€ä»Šå›ã¯`Ingress`ãŠã‚ˆã³`Ingress-Controller`ã‚’ç”¨ã„ã¦é©åˆ‡ã«å¤–éƒ¨ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’å†…éƒ¨Serviceã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹æ–¹æ³•ã‚’å–ã‚Šã¾ã™ã€‚

åŒæ™‚ã«ã€cert-managerã‚’åˆ©ç”¨ã—ã¦TLSè¨¼æ˜æ›¸ã®ç™ºè¡ŒãŠã‚ˆã³ç®¡ç†ã‚’è‡ªå‹•çš„ã«è¡Œã†ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã‚’è¡Œã„ã¾ã™ã€‚ä¸€èˆ¬çš„ãªWebã‚µãƒ¼ãƒ“ã‚¹ã¯HTTPSãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚å½“ç„¶ã€Kibanaã‚‚ãã®ä¾‹å¤–ã§ã¯ãªãã€å¿…ç„¶çš„ã«TLSç½²åãŒå¿…è¦ã¨ãªã‚Šã¾ã™ã€‚ãã“ã§ç½²åã‚„ç®¡ç†ã‚’è‡ªå‹•ã§è¡Œãˆã‚‹cert-managerã¯å¿…è¦ä¸å¯æ¬ ã§ã™ã—ã€ã“ã®è¨˜äº‹ã§ã‚‚è»½ãä½¿ã„æ–¹ã‚’èª¬æ˜ã—ã¾ã™ã€‚

### 1.3.1 Ingress Controllerã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹
`Ingress`ã®Serviceã‚’æ‰±ã†ã«ã¯Ingress ControllerãŒå¿…è¦ã§ã™ã€‚Ingress Controllerã¯å¤šæ•°å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ãŒã€ã“ã®å ´åˆã¯Ingress Nginx Controller(https://kubernetes.github.io/ingress-nginx/deploy/)ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
:::message
ã“ã“ã§ã¯helmã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ã„ã¾ã™ãŒã€ä»–ã®æ–¹æ³•ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚è©³ã—ãã¯å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã”å‚ç…§ãã ã•ã„ã€‚
:::
ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚
```
helm upgrade --install ingress-nginx ingress-nginx \
  --repo https://kubernetes.github.io/ingress-nginx \
  --namespace ingress-nginx --create-namespace
```
ã“ã‚Œã§ã€`ingress-nginx`namespaceã«Ingress Nginx ControllerãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¾ã—ãŸã€‚
`kubectl get svc -n ingress-nginx`ã§ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

```
NAME                                 TYPE           CLUSTER-IP       EXTERNAL-IP    PORT(S)                      AGE
ingress-nginx-controller             LoadBalancer   10.128.229.175   xx.xx.xxx.xx   80:30350/TCP,443:31867/TCP   43h
ingress-nginx-controller-admission   ClusterIP      10.128.142.155   <none>         443/TCP                      43h
```
`ingress-nginx-controller`ã®`EXTERNAL-IP`ã®å€¤ã¯å¾Œã»ã©ä½¿ç”¨ã—ã¾ã™ã€‚

### 1.3.2 cert-managerã¨Let's Encryptã§Kibanaã®TLSèªè¨¼ã‚’è¡Œã†

CAæ©Ÿé–¢ã«ã‚ˆã‚‹TLSèªè¨¼ã«å¿…è¦ãªè¨¼æ˜æ›¸ã®ç™ºè¡Œã¯é«˜é¡ãªè²»ç”¨ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

ã§ã™ãŒã€ç¾åœ¨ã¯Let's EncryptãŒç„¡æ–™ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‹ã¤è‡ªå‹•åŒ–ã•ã‚ŒãŸè¨¼æ˜æ›¸ã®ç™ºè¡Œã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ã¦ã„ã‚‹ã®ã§ã€cert-managerã§è‡ªå‹•çš„ã«Let's Encrypt(HTTP01 Challenge)ã«ã‚ˆã‚‹è¨¼æ˜æ›¸ã®ç™ºè¡Œã¨æœŸé™åˆ‡ã‚Œã®è¨¼æ˜æ›¸ã®æ›´æ–°ã‚’è¡Œãˆã‚‹ã‚ˆã†ã«è¨­å®šã—ã¾ã™ã€‚

ã¾ãšã¯cert-managerã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚ã™ã§ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹æ–¹ã¯æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«ãŠé€²ã¿ãã ã•ã„ã€‚

:::message
ã“ã“ã§ã¯helmã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ã„ã¾ã™ãŒã€`yaml`ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’åˆ©ç”¨ã—ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚è©³ã—ãã¯cert-managerã®å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
:::

```bash
$ helm repo add jetstack https://charts.jetstack.io --force-update
>> "jetstack" has been added to your repositories

$ helm repo update
>> Successfully got an update from the "jetstack" chart repository

$ helm install \
  cert-manager jetstack/cert-manager \
  --namespace cert-manager \
  --create-namespace \
  --version v1.15.1 \
  --set crds.enabled=true
>> cert-manager v1.15.1 has been deployed successfully!
```
æ¬¡ã«ã€`ClusterIssuer`ã‚’ä½œæˆã—ã¾ã™ã€‚æ·±å…¥ã‚Šã¯ã—ã¾ã›ã‚“ãŒã€cert-managerã®Issuerã«ã¯äºŒç¨®é¡ã‚ã‚Šã€ã“ã“ã§ã¯ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¬ãƒ™ãƒ«ã®ã‚¹ã‚³ãƒ¼ãƒ—ã§ä½¿ç”¨ã§ãã‚‹ClusterIssuerã‚’ä½¿ã„ã¾ã™ã€‚

æ³¨æ„ã™ã¹ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’ç°¡å˜ã«èª¬æ˜ã—ã¾ã™ã€‚
- `acme.email`:è‡ªåˆ†ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚
- `acme.server`:ä½¿ç”¨ã™ã‚‹acmeã®ã‚µãƒ¼ãƒãƒ¼ã€‚ã“ã“ã§ã¯Let's Encryptã®Prod(Production)ã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ãŒã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆå›æ•°ã«åˆ¶é™ãŒã‚ã‚‹ã®ã§ã€ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã¯Let's Encryptã®Testç’°å¢ƒ(https://acme-staging-v02.api.letsencrypt.org/directory)ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚

:::message alert
Let's Encryptã®ãƒ†ã‚¹ãƒˆç’°å¢ƒã«ã¦ç™ºè¡Œã•ã‚Œã‚‹è¨¼æ˜æ›¸ã¯ç™ºè¡Œå´ãŒå®Œå…¨ãªæƒ…å ±ã‚’è¨˜è¿°ã—ã¦ã„ãªã„ã®ã§æ­£å¼ã«ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚ãã¾ã§ãƒ†ã‚¹ãƒˆç”¨ã¨ã—ã¦ã”åˆ©ç”¨ãã ã•ã„ã€‚
:::
- `acme.solvers[0].http01.ingress.class`:ä½¿ç”¨ã—ã¦ã„ã‚‹Ingress Controllerã®å€¤ã«ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚ã“ã“ã§ã¯`nginx`ã«ãªã‚Šã¾ã™ã€‚ã“ã‚Œã§cert-managerã¯port 80ã«ingressã‚’é…ç½®ã—ã€acmeã‚µãƒ¼ãƒãƒ¼ã«HTTP-01èªè¨¼ã‚’ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®èª¿æ•´ãŒçµ‚ã‚ã‚Šã¾ã—ãŸã‚‰applyã—ã¾ã—ã‚‡ã†ã€‚
```bash
kubectl apply -f clusterissuer.yaml
```
ã¤ã„ã§ã«ç¢ºèªã‚‚ã—ã¦ã¿ã¾ã™ã€‚
```bash
$ kubectl get ClusterIssuer

>>letsencrypt-prod   True    42h
```

# Kibanaã‚’Ingressã§å…¬é–‹ã™ã‚‹
æœ€å¾Œã®æ‰‹é †ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§`ingress`ã‚’ä½œæˆã—ã¾ã™ã€‚

æ³¨æ„ã™ã¹ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’ä»¥ä¸‹ã«èª¬æ˜ã—ã¾ã™ã€‚
- `your domain`:ãƒ‰ãƒ¡ã‚¤ãƒ³åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã‚‚ã—æ‰‹æŒã¡ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã‚‰ã€ãƒ†ã‚¹ãƒˆç”¨é€”ã«`nip.io`ã‚’åˆ©ç”¨ã§ãã¾ã™ã€‚å…ˆã»ã©å–å¾—ã—ãŸ`ingress-nginx-controller`Serviceã®`External-IP`ã®å€¤ã‚’`xx.xx.xxx.xx.nip.io`ã®ã‚ˆã†ã«å½“ã¦ã¯ã‚ã‚‹ã“ã¨ã§DNSãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãŒã§ãã¾ã™ã€‚è©³ã—ãã¯ https://nip.io/ ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
- `your ingress controller`:ä½¿ç”¨ã—ã¦ã„ã‚‹Ingress Controllerã®class nameã«ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚ã“ã“ã§ã¯`nginx`ã§ã™ãƒ»

# 2.åé›†å´ã®ä½œæ¥­
## 2.1 `namespace`ã‚’ä½œæˆã™ã‚‹
ä»–ã®ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãŒ`default`ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€namespaceã‚’`default`ã¨åˆ†ã‘ã¦`fluent`ã§ä½œæˆã—ã¾ã™ã€‚
``` yaml:fluent-namespace.yaml
kind: Namespace
apiVersion: v1
metadata:
  name: fluent
```
applyã—ã¾ã™ã€‚
```bash
kubectl apply -f fluent-namespace.yaml
```
## 2.2 fluentdã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›´ã™ã‚‹ãŸã‚ã®`ConfigMap`ã‚’ä½œæˆã™ã‚‹
fluentdã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§`var/log/containers/`ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦jsonç”¨ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã‚Œã¯dockerã®ãƒ­ã‚°ãŒjsonå½¢å¼ã§ã‚ã‚‹ãŸã‚ã§ã™ã€‚
ã§ã™ãŒã€ã‚‚ã—containerdã‚„cri-oã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã€ãƒ­ã‚°ã®å½¢å¼ã¯dockerã®ãã‚Œã¨å…¨ãç•°ãªã‚Šã¾ã™ã€‚ã‚ˆã£ã¦ã€å°‚ç”¨ã®criãƒ‘ãƒ¼ã‚µãƒ¼(https://github.com/fluent/fluent-plugin-parser-cri)ã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

ã©ã®ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã¹ããªã®ã‹ä¸ç¢ºã‹ã§ã—ãŸã‚‰ã€`kubectl exec -it yourpodname -- sh`ã§podã«æ¥ç¶šã—ã€`/var/log/`ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¦—ã„ã¦ã¿ã¦ãã ã•ã„ã€‚ã‚‚ã—ãƒ­ã‚°ã®å½¢å¼ãŒ

```
2020-10-10T00:10:00.333333333Z stdout F Hello Fluentd
```
ã®ã‚ˆã†ã«ãªã£ã¦ã„ãŸã‚‰ã€ä»¥ä¸‹ã‚’å‚è€ƒã«fluentdã®è¨­å®šã‚’å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚ã‚‚ã—jsonå½¢å¼ã§ã—ãŸã‚‰ã“ã®æ‰‹é †ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚

`ConfigMap`ç”¨ã®ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚
```yaml:fluent-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: tail-container-parse-conf
  namespace: fluent
data:
  tail_container_parse.conf: |
```
applyã—ã¾ã™ã€‚
```
kubectl apply -f fluent-configmap.yaml
```
:::message
è¿½è¨˜ï¼šã“ã®`ConfigMap`ãŒå¤‰æ›´ã—ã¦ã„ã‚‹ã®ã¯å¾Œã»ã©ä½¿ç”¨ã™ã‚‹fluentd-kubernetes-daemonset(https://github.com/fluent/fluentd-kubernetes-daemonset)ã‚¤ãƒ¡ãƒ¼ã‚¸ã®`/fluentd/etc/`ä»¥ä¸‹ã«ã‚ã‚‹`tail_container_parse.conf`ã§ã™ã€‚ã“ã¡ã‚‰(https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.17/debian-elasticsearch8/conf)ã§ã™ã¹ã¦ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–²è¦§ã§ãã¾ã™ã€‚
:::

## 2.3 Elastic Stackã‚¯ãƒ©ã‚¹ã‚¿ã®æƒ…å ±ã‚’è¨˜è¼‰ã™ã‚‹Secretã‚’ä½œæˆã™ã‚‹
fluentdãŒElasticSearchã«ãƒ­ã‚°ã‚’é€ä¿¡ã™ã‚‹éš›ã«ã¯ElasticSearchã®ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ãŒå¿…è¦ã«ãªã‚Šã¾ã™ã€‚ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ç›´æ¥fluentdã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜è¿°ã™ã‚‹ã®ã¯å®‰å…¨æ€§ã¨æŸ”è»Ÿæ€§ã«æ¬ ã‘ã¾ã™ã®ã§ã€ã“ã“ã§ã¯Secretã‚’ä½¿ç”¨ã—ã¦å…ˆã»ã©å–å¾—ã—ãŸãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’è¨˜è¿°ã—ã¾ã™ã€‚

ã¾ãšã€Opaqueã‚¿ã‚¤ãƒ—ã®Secretã«æ ¼ç´ã•ã‚Œã‚‹æƒ…å ±ã¯`base64`ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã®ã§ã€å…ˆã«ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§`base64`ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¾ã—ã‚‡ã†ã€‚
```bash
echo -n 'fluentd' | base64
```
```bash
echo -n 'mypassword' | base64
```

:::message
æ³¨ï¼š`''`ã¯å–ã‚Šå¤–ã•ãªã„ã§ãã ã•ã„ã€‚
:::
æ¬¡ã«ã€å…ˆã»ã©ã®ã‚³ãƒãƒ³ãƒ‰ã§å‡ºåŠ›ã•ã‚ŒãŸã‚¢ã‚«ã‚¦ãƒ³ãƒˆã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰çµæœã‚’ã€ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®è©²å½“é …ç›®ã«å…¥åŠ›ã—ã¾ã™ã€‚

applyã—ã¾ã™ã€‚
```bash
kubectl apply -f fluent-secret.yaml
```

## 2.4 fluentdã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹
ã„ã‚ˆã„ã‚ˆå¤§è©°ã‚ã§ã™ã€‚ä»¥ä¸‹ã«å¤‰æ›´ã™ã¹ãè¨­å®šã®ä¸€è¦§ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚
- `containers.env.name: FLUENT_ELASTICSEARCH_HOST`
  - å…ˆã»ã©å–å¾—ã—ãŸElasticsearchã®EXTERNAL-IPã‚’è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚
- 

```yaml:fluent.yaml
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd
  namespace: fluent
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: fluentd
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - namespaces
  verbs:
  - get
  - list
  - watch

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: fluentd
roleRef:
  kind: ClusterRole
  name: fluentd
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: fluentd
  namespace: fluent
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: fluent
  labels:
    k8s-app: fluentd-logging
    version: v1
spec:
  selector:
    matchLabels:
      k8s-app: fluentd-logging
      version: v1
  template:
    metadata:
      labels:
        k8s-app: fluentd-logging
        version: v1
    spec:
      serviceAccount: fluentd
      serviceAccountName: fluentd
      tolerations:
      - key: node-role.kubernetes.io/control-plane
        effect: NoSchedule
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1.17-debian-elasticsearch8-1
        env:
          - name: K8S_NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          - name:  FLUENT_ELASTICSEARCH_HOST
            value: "45.79.244.31"
          - name:  FLUENT_ELASTICSEARCH_PORT
            value: "9200"
          - name: FLUENT_ELASTICSEARCH_SCHEME
            value: "https"
          - name: FLUENTD_SYSTEMD_CONF
            value: disable
          # Option to configure elasticsearch plugin with self signed certs
          # ================================================================
          - name: FLUENT_ELASTICSEARCH_SSL_VERIFY
            value: "false"
          # Option to configure elasticsearch plugin with tls
          # ================================================================
          - name: FLUENT_ELASTICSEARCH_SSL_VERSION
            value: "TLSv1_2"
          # X-Pack Authentication
          # =====================
          - name: FLUENT_ELASTICSEARCH_USER
            value: "elastic"
          - name: FLUENT_ELASTICSEARCH_PASSWORD
            value: "k29mg54NteJvmJsf"
          - name: FLUENT_CONTAINER_TAIL_EXCLUDE_PATH
            value: /var/log/containers/fluent*
          - name: FLUENT_CONTAINER_TAIL_PARSER_TYPE
            value: /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/
          - name: FLUENT_CONTAINER_TAIL_PATH
            value: /var/log/containers/abconvert*.log
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 200Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        # - name: containers-conf-volume
        #   mountPath: /fluentd/etc/kubernetes/containers.conf
        #   subPath: containers.conf
        # When actual pod logs in /var/lib/docker/containers, the following lines should be used.
        - name: dockercontainerlogdirectory
          mountPath: /var/lib/docker/containers
          readOnly: true
        # When actual pod logs in /var/log/pods, the following lines should be used.
        # - name: dockercontainerlogdirectory
        #   mountPath: /var/log/pods
        #   readOnly: true
      terminationGracePeriodSeconds: 30
      volumes:
      # - name: containers-conf-volume
      #   configMap:
      #     name: containers-conf
      # - name: nodejs-conf-volume
      #   configMap:
      #     name: nodejs-conf
      # - name: tail-container-parse-conf-volume
      #   configMap:
      #     name: tail-container-parse-conf
      - name: varlog
        hostPath:
          path: /var/log
      # When actual pod logs in /var/lib/docker/containers, the following lines should be used.
      - name: dockercontainerlogdirectory
        hostPath:
          path: /var/lib/docker/containers
      # When actual pod logs in /var/log/pods, the following lines should be used.
      # - name: dockercontainerlogdirectory
      #   hostPath:
      #     path: /var/log/pods
```

